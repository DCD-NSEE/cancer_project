{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlGZnyBQ_dG0"
   },
   "source": [
    "# **Data Dictionary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9AX9AZc_gY7"
   },
   "source": [
    "* **SEXO**: Gender of the patient (int = 1).\n",
    "\n",
    "   1 - MALE;\n",
    "   \n",
    "   2 - FEMALE.\n",
    "\n",
    "* **IDADE**: Patient's age (int = 3).\n",
    "\n",
    "* **ESCOLARI**: Code for patient education (int = 1).\n",
    "\n",
    "   1 - ILLITERATE;\n",
    "   \n",
    "   2 - ELEMENTARY SCHOOL INCOMPLETE;\n",
    "   \n",
    "   3 - ELEMENTARY SCHOOL COMPLETE;\n",
    "   \n",
    "   4 - HIGH SCHOOL;\n",
    "   \n",
    "   5 - UNIVERSITY EDUCATION;\n",
    "   \n",
    "   9 - IGNORED.\n",
    "\n",
    "* **UFNASC**: UF of birth (char = 2). Other options: SI - No information; OP - Another country.\n",
    "\n",
    "* **UFRESID**: UF of residence (char = 2). Other options: OP - Another country.\n",
    "\n",
    "* **IBGE**: Code of the patient's city of residence according to IBGE with check digit (char = 7).\n",
    "\n",
    "* **CIDADE**: City of residence of the patient (char = 200).\n",
    "\n",
    "* **CATEATEND**: Category of diagnosis assistance (int = 1).\n",
    "\n",
    "   1 - HEALTH INSURANCE;\n",
    "   \n",
    "   2 - SUS;\n",
    "   \n",
    "   3 - PRIVATE;\n",
    "   \n",
    "   9 - NO INFORMATION.\n",
    "\n",
    "* **DTCONSULT**: Date of the first consultation (date = 10). Format: DD/MM/YYYY\n",
    "\n",
    "* **CLINICA**: Clinic code (int = 2).\n",
    "\n",
    "   1 - ALLERGY / IMMUNOLOGY;\n",
    "\n",
    "   2 - HEART SURGERY;\n",
    "   \n",
    "   3 - HEAD AND NECK SURGERY;\n",
    "   \n",
    "   4 - GENERAL SURGERY;\n",
    "   \n",
    "   5 - PEDIATRIC SURGERY;\n",
    "   \n",
    "   6 - PLASTIC SURGERY;\n",
    "   \n",
    "   7 - THORAXIC SURGERY;\n",
    "   \n",
    "   8 - VASCULAR SURGERY;\n",
    "   \n",
    "   9 - CLINICA MEDICA;\n",
    "   \n",
    "   10 - DERMATOLOGY;\n",
    "   \n",
    "   11 - ENDOCRINOLOGY;\n",
    "   \n",
    "   12 - GASTRO SURGERY;\n",
    "   \n",
    "   13 - GASTROENTEROLOGY;\n",
    "   \n",
    "   14 - MANAGEMENT;\n",
    "   \n",
    "   15 - GYNECOLOGY;\n",
    "   \n",
    "   16 - GYNECOLOGY / OBSTETRIC;\n",
    "   \n",
    "   17 - HEMATOLOGY;\n",
    "   \n",
    "   18 - INFECTOLOGY;\n",
    "   \n",
    "   19 - NEPHROLOGY;\n",
    "   \n",
    "   20 - NEUROSURGERY;\n",
    "   \n",
    "   21 - NEUROLOGY;\n",
    "   \n",
    "   22 - OPHTHALMOLOGY;\n",
    "   \n",
    "   23 - SURGICAL ONCOLOGY;\n",
    "   \n",
    "   24 - CLINICAL ONCOLOGY;\n",
    "   \n",
    "   25 - PEDIATRIC ONCOLOGY;\n",
    "   \n",
    "   26 - ORTHOPEDICS;\n",
    "   \n",
    "   27 - OTORHINOLARYNGOLOGY;\n",
    "   \n",
    "   28 - PEDIATRICS;\n",
    "   \n",
    "   29 - PNEUMOLOGY;\n",
    "   \n",
    "   30 - PROCTOLOGY;\n",
    "   \n",
    "   31 - RADIOTHERAPY;\n",
    "   \n",
    "   32 - UROLOGY;\n",
    "   \n",
    "   33 - MASTOLOGY;\n",
    "   \n",
    "   34 - CUTANEA ONCOLOGY;\n",
    "   \n",
    "   35 - PELVIC SURGERY;\n",
    "   \n",
    "   36 - ABDOMINAL SURGERY;\n",
    "   \n",
    "   37 - DENTISTRY;\n",
    "   \n",
    "   38 - HEPATIC TRANSPLANTATION;\n",
    "   \n",
    "   99 - IGNORED.\n",
    "\n",
    "* **DIAGPREV**: Diagnosis and previous treatment (int = 1).\n",
    "\n",
    "   1 - WITHOUT DIAGNOSIS / WITHOUT TREATMENT;\n",
    "\n",
    "   2 - WITH DIAGNOSIS / WITHOUT TREATMENT;\n",
    "\n",
    "   3 - WITH DIAGNOSIS / WITH TREATMENT;\n",
    "\n",
    "   4 - OTHERS.\n",
    "\n",
    "* **DTDIAG**: Date of diagnosis (date = 10). Format: DD/MM/YYYY\n",
    "\n",
    "* **BASEDIAG**: Code of the diagnosis base (int = 1).\n",
    "\n",
    "   1 - CLINICAL EXAMINATION;\n",
    "\n",
    "   2 - NON-MICROSCOPIC AUXILIARY RESOURCES;\n",
    "\n",
    "   3 - MICROSCOPIC CONFIRMATION;\n",
    "\n",
    "   4 - NO INFORMATION.\n",
    "\n",
    "* **TOPO**: Topography code (char = 4). Format: C999\n",
    "\n",
    "* **TOPOGRUP**: Topography group (char = 3). Format: C99\n",
    "\n",
    "* **DESCTOPO**: Topography description (char = 80).\n",
    "\n",
    "* **MORFO**: Morphology code (char = 5). Format: 99999\n",
    "\n",
    "* **DESCMORFO**: Description of the morphology (char = 80).\n",
    "\n",
    "* **EC**: Clinical stage (char = 5).\n",
    "\n",
    "* **ECGRUP**: Clinical staging group (char = 3).\n",
    "\n",
    "   0 - Primary tumors, classified as in situ;\n",
    "\n",
    "   I - Localized tumors;\n",
    "\n",
    "   II - Tumors with regional involvement by direct extension;\n",
    "\n",
    "   III - Tumors with regional involvement of lymph nodes;\n",
    "\n",
    "   IV - Tumors with distant metastasis;\n",
    "\n",
    "   X - For tumors not evaluated by the responsible professional or without information on staging noted in the medical record;\n",
    "\n",
    "   Y - For tumors in which the TNM classification is not applied. These are non-solid tumors (for example, leukemias).\n",
    "\n",
    "* **T**: TNM - T classification (char = 5).\n",
    "\n",
    "* **N**: TNM - N classification (char = 5).\n",
    "\n",
    "* **M**: TNM - M classification (char = 3).\n",
    "\n",
    "* **PT**: Post-surgical staging (char = 5).\n",
    "\n",
    "* **PN**: Post-surgical staging (char = 5).\n",
    "\n",
    "* **PM**: Post-surgical staging (char = 3).\n",
    "\n",
    "* **S**: TNM - S classification (int = 1). Domain: 0; 1; 2; 3; 8 - DOES NOT APPLY; 9 - X\n",
    "\n",
    "* **G**: TNM Classification - G (Degree) (char = 5).\n",
    "   Domain (except C40, C41, C381, C382, C383, C47, C48 and C49): 0; 1; two; 3; 4; 8 - DOES NOT APPLY; 9 - X.\n",
    "\n",
    "   Domain (C40, C41, C381, C382, C383, C47, C48 and C49 only): HIGH; LOW; 8 - DOES NOT APPLY; 9 - X.\n",
    "\n",
    "* **LOCALTNM**: TNM Classification - Location (int = 1).\n",
    "\n",
    "   1 - SUPERIOR;\n",
    "\n",
    "   2 - MEDIUM;\n",
    "\n",
    "   3 - LOWER;\n",
    "\n",
    "   8 - NOT APPLICABLE;\n",
    "\n",
    "   9 - X.\n",
    "\n",
    "* **IDMITOTIC**: TNM Classification - Mitotic Index (int = 1).\n",
    "\n",
    "   1 - HIGH;\n",
    "      \n",
    "   2 - LOW;\n",
    "      \n",
    "   8 - NOT APPLICABLE;\n",
    "      \n",
    "   9 - X.\n",
    "\n",
    "* **PSA**: TNM - PSA classification (int = 1).\n",
    "\n",
    "   1 - LESS THAN 10;\n",
    "      \n",
    "   2 - GREATER OR EQUAL TO 10 AND LESS THAN 20;\n",
    "      \n",
    "   3 - GREATER OR EQUAL TO 20;\n",
    "      \n",
    "   8 - NOT APPLICABLE;\n",
    "      \n",
    "   9 - X.\n",
    "\n",
    "* **GLEASON**: TNM - Gleason classification (int = 1).\n",
    "\n",
    "   1 - SMALLER OR EQUAL TO 6;\n",
    "      \n",
    "   2 - EQUAL TO 7;\n",
    "      \n",
    "   3 - GREATER OR EQUAL TO 8;\n",
    "      \n",
    "   8 - NOT APPLICABLE;\n",
    "      \n",
    "   9 - X.\n",
    "\n",
    "* **OUTRACLA**: Another classification of staging (char = 20).\n",
    "\n",
    "* **META01**: Metastasis (char = 3). Format: C99\n",
    "\n",
    "* **META02**: Metastasis (char = 3). Format: C99\n",
    "\n",
    "* **META03**: Metastasis (char = 3). Format: C99\n",
    "\n",
    "* **META04**: Metastasis (char = 3). Format: C99\n",
    "\n",
    "* **DTTRAT**: Treatment start date (date = 10). Format: DD/MM/YYYY\n",
    "\n",
    "* **NAOTRAT**: Reason code for not carrying out the treatment (int = 1).\n",
    "\n",
    "   1 - REFUSAL OF TREATMENT;\n",
    "      \n",
    "   2 - ADVANCED DISEASE, LACK OF CLINICAL CONDITIONS;\n",
    "      \n",
    "   3 - OTHER ASSOCIATED DISEASES;\n",
    "      \n",
    "   4 - TREATMENT ABANDONMENT;\n",
    "      \n",
    "   5 - CANCER DEATH;\n",
    "      \n",
    "   6 - DEATH FOR OTHER CAUSES;\n",
    "      \n",
    "   7 - OTHER;\n",
    "      \n",
    "   8 - NOT APPLICABLE (IF HAVE TREATMENT);\n",
    "      \n",
    "   9 - NO INFORMATION.\n",
    "\n",
    "* **TRATAMENTO**: Combination code of the treatments (char = 1).\n",
    "\n",
    "   A - Surgery;\n",
    "      \n",
    "   B - Radiotherapy;\n",
    "      \n",
    "   C - Chemotherapy;\n",
    "      \n",
    "   D - Surgery + Radiotherapy;\n",
    "      \n",
    "   E - Surgery + Chemotherapy;\n",
    "      \n",
    "   F - Radiotherapy + Chemotherapy;\n",
    "      \n",
    "   G - Surgery + Radio + Chemo;\n",
    "      \n",
    "   H - Surgery + Radio + Chemo + Hormone;\n",
    "      \n",
    "   I - Other treatment combinations;\n",
    "      \n",
    "   J - No treatment.\n",
    "\n",
    "* **TRATHOSP**: Combination code of treatments at the hospital (char = 1).\n",
    "\n",
    "   A - Surgery;\n",
    "      \n",
    "   B - Radiotherapy;\n",
    "      \n",
    "   C - Chemotherapy;\n",
    "      \n",
    "   D - Surgery + Radiotherapy;\n",
    "      \n",
    "   E - Surgery + Chemotherapy;\n",
    "      \n",
    "   F - Radiotherapy + Chemotherapy;\n",
    "      \n",
    "   G - Surgery + Radio + Chemo;\n",
    "      \n",
    "   H - Surgery + Radio + Chemo + Hormone;\n",
    "      \n",
    "   I - Other treatment combinations;\n",
    "      \n",
    "   J - No treatment.\n",
    "\n",
    "* **TRATFANTES**: Combination code of treatments performed before / during admission outside the hospital (char = 1).\n",
    "\n",
    "   A - Surgery;\n",
    "      \n",
    "   B - Radiotherapy;\n",
    "      \n",
    "   C - Chemotherapy;\n",
    "      \n",
    "   D - Surgery + Radiotherapy;\n",
    "      \n",
    "   E - Surgery + Chemotherapy;\n",
    "      \n",
    "   F - Radiotherapy + Chemotherapy;\n",
    "      \n",
    "   G - Surgery + Radio + Chemo;\n",
    "      \n",
    "   H - Surgery + Radio + Chemo + Hormone;\n",
    "      \n",
    "   I - Other treatment combinations;\n",
    "      \n",
    "   J - No treatment;\n",
    "\n",
    "   K - No information.\n",
    "\n",
    "* **TRATFAPOS**: Combination code of treatments performed after admission outside the hospital (char = 1).\n",
    "\n",
    "   A - Surgery;\n",
    "      \n",
    "   B - Radiotherapy;\n",
    "      \n",
    "   C - Chemotherapy;\n",
    "      \n",
    "   D - Surgery + Radiotherapy;\n",
    "      \n",
    "   E - Surgery + Chemotherapy;\n",
    "      \n",
    "   F - Radiotherapy + Chemotherapy;\n",
    "      \n",
    "   G - Surgery + Radio + Chemo;\n",
    "      \n",
    "   H - Surgery + Radio + Chemo + Hormone;\n",
    "      \n",
    "   I - Other treatment combinations;\n",
    "      \n",
    "   J - No treatment;\n",
    "\n",
    "   K - No information.\n",
    "\n",
    "* **NENHUM**: Treatment received at the hospital = none (int = 1). 0 - NO; 1 - YES\n",
    "\n",
    "* **CIRURGIA**: Treatment received at the hospital = surgery (int = 1). 0 - NO; 1 - YES\n",
    "\n",
    "* **RADIO**: Treatment received at the hospital = radiotherapy (int = 1). 0 - NO; 1 - YES\n",
    "\n",
    "* **QUIMIO**: Treatment received at the hospital = chemotherapy (int = 1). 0 - NO; 1 - YES\n",
    "\n",
    "* **HORMONIO**: Treatment received at the hospital = hormone therapy (int = 1). 0 - NO; 1 - YES\n",
    "\n",
    "* **TMO**: Treatment received at the hospital = tmo (int = 1). 0 - NO; 1 - YES\n",
    "\n",
    "* **IMUNO**: Treatment received at the hospital = immunotherapy (int = 1). 0 - NO; 1 - YES\n",
    "\n",
    "* **OUTROS**: Treatment received at the hospital = others (int = 1). 0 - NO; 1 - YES\n",
    "\n",
    "* **NENHUMANT**: Treatment received outside the hospital and before admission = none (int = 1). 0 - NO; 1 - YES\n",
    "\n",
    "* **CIRURANT**: Treatment received outside the hospital and before admission = surgery (int = 1). 0 - NO; 1 - YES\n",
    "\n",
    "* **RADIOANT**: Treatment received outside the hospital and before admission = radiotherapy (int = 1). 0 - NO; 1 - YES\n",
    "\n",
    "* **QUIMIOANT**: Treatment received outside the hospital and before admission = chemotherapy (int = 1). 0 - NO; 1 - YES\n",
    "\n",
    "* **HORMOANT**: Treatment received outside the hospital and before admission = hormone therapy (int = 1). 0 - NO; 1 - YES\n",
    "\n",
    "* **TMOANT**: Treatment received outside the hospital and before admission = tmo (int = 1). 0 - NO; 1 - YES\n",
    "\n",
    "* **IMUNOANT**: Treatment received outside the hospital and before admission = immunotherapy (int = 1). 0 - NO; 1 - YES\n",
    "\n",
    "* **OUTROANT**: Treatment received outside the hospital and before admission = others (int = 1). 0 - NO; 1 - YES\n",
    "\n",
    "* **NENHUMAPOS**: Treatment received outside the hospital and during / after admission = none (int = 1). 0 - NO; 1 - YES\n",
    "\n",
    "* **CIRURAPOS**: Treatment received outside the hospital and during / after admission = surgery (int = 1). 0 - NO; 1 - YES\n",
    "\n",
    "* **RADIOAPOS**: Treatment received outside the hospital and during / after admission = radiotherapy (int = 1). 0 - NO; 1 - YES\n",
    "\n",
    "* **QUIMIOAPOS**: Treatment received outside the hospital and during / after admission = chemotherapy (int = 1). 0 - NO; 1 - YES\n",
    "\n",
    "* **HORMOAPOS**: Treatment received outside the hospital and during / after admission = hormone therapy (int = 1). 0 - NO; 1 - YES\n",
    "\n",
    "* **TMOAPOS**: Treatment received outside the hospital and during / after admission = tmo (int = 1). 0 - NO; 1 - YES\n",
    "\n",
    "* **IMUNOAPOS**: Treatment received outside the hospital and during / after admission = immunotherapy (int = 1). 0 - NO; 1 - YES\n",
    "\n",
    "* **OUTROAPOS**: Treatment received outside the hospital and during / after admission = other (int = 1). 0 - NO; 1 - YES\n",
    "\n",
    "* **DTULTINFO**: Date of the patient's last information (date = 10). Format: DD/MM/YYYY\n",
    "\n",
    "* **ULTINFO**: Last information about the patient (int = 1).\n",
    "\n",
    "   1 - ALIVE, WITH CANCER;\n",
    "      \n",
    "   2 - ALIVE, WITHOUT OTHER SPECIFICATIONS;\n",
    "      \n",
    "   3 - CANCER DEATH;\n",
    "      \n",
    "   4 - DEATH FOR OTHER CAUSES, WITHOUT OTHER SPECIFICATIONS.\n",
    "\n",
    "* **CONSDIAG**: Difference in days between the dates of consultation and diagnosis (num = days).\n",
    "\n",
    "* **TRATCONS**: Difference in days between the dates of consultation and treatment (num = days).\n",
    "\n",
    "* **DIAGTRAT**: Difference in days between the dates of treatment and diagnosis (num = days).\n",
    "\n",
    "* **ANODIAG**: Year of diagnosis (int = 4). Format: 9999\n",
    "\n",
    "* **CICI**: Childhood tumor (char = 5).\n",
    "\n",
    "* **CICIGRUP**: Childhood tumor - Group (char = 80).\n",
    "\n",
    "* **CICISUBGRU**: Childhood tumor - Subgroup (char = 80).\n",
    "\n",
    "* **FAIXAETAR**: Age range of the patient (char = 5).\n",
    "\n",
    "* **LATERALI**: Laterality (int = 1).\n",
    "\n",
    "   1 - RIGHT;\n",
    "   \n",
    "   2 - LEFT;\n",
    "      \n",
    "   3 - BILATERAL;\n",
    "      \n",
    "   8 - NOT APPLICABLE.\n",
    "\n",
    "* **INSTORIG**: Home institution (char = 200). Mandatory only if DIAGPREV = 03 - WITH DIAGNOSIS / WITH TREATMENT.\n",
    "\n",
    "* **DRS**: Regional Health Departments (char = 200).\n",
    "\n",
    "* **RRAS**: Regional Health Care Network (char = 200).\n",
    "\n",
    "* **DTPREENCH**: Completion date (date = 10). Format: DD/MM/YYYY\n",
    "\n",
    "* **REGISTRADO**: \n",
    "\n",
    "* **DTRECIDIVA**: Date of the last occurrence of recurrence (date = 10). Format: DD/MM/YYYY\n",
    "\n",
    "* **RECNENHUM**: Without recurrence (int = 1). 0 - No; 1 - Yes\n",
    "\n",
    "* **RECLOCAL**: Local recurrence (int = 1). 0 - No; 1 - Yes\n",
    "\n",
    "* **RECREGIO**: Regional recurrence (int = 1). 0 - No; 1 - Yes\n",
    "\n",
    "* **RECDIST**: Distance / metastasis recurrence (int = 1). 0 - No; 1 - Yes\n",
    "\n",
    "* **REC01**: Recurrence / metastasis local (char = 3). Format: C99\n",
    "\n",
    "* **REC02**: Recurrence / metastasis local (char = 3). Format: C99\n",
    "\n",
    "* **REC03**: Recurrence / metastasis local (char = 3). Format: C99\n",
    "\n",
    "* **REC04**: Recurrence / metastasis local (char = 3). Format: C99\n",
    "\n",
    "* **HABILIT2**: Hospital qualification (int = 1). CACON or UNACON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wc8O5Laa3A7Q"
   },
   "source": [
    "# **Libraries**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSUkkbHy3A7R"
   },
   "source": [
    "Import of all libraries used in the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:01:58.092391Z",
     "iopub.status.busy": "2021-12-09T16:01:58.092078Z",
     "iopub.status.idle": "2021-12-09T16:02:14.079468Z",
     "shell.execute_reply": "2021-12-09T16:02:14.079468Z"
    },
    "id": "xAGaKGRi9ZLd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Graphs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import pickle # Save models\n",
    "seed = 10 # seed for the random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:02:14.083715Z",
     "iopub.status.busy": "2021-12-09T16:02:14.082674Z",
     "iopub.status.idle": "2021-12-09T16:02:16.432944Z",
     "shell.execute_reply": "2021-12-09T16:02:16.432944Z"
    },
    "id": "ZQwNgH4x9ZLe"
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, MaxAbsScaler, QuantileTransformer, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:02:16.437304Z",
     "iopub.status.busy": "2021-12-09T16:02:16.435943Z",
     "iopub.status.idle": "2021-12-09T16:02:28.518404Z",
     "shell.execute_reply": "2021-12-09T16:02:28.517404Z"
    },
    "id": "a1395Agw9ZLf"
   },
   "outputs": [],
   "source": [
    "# Classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, roc_curve, roc_auc_score, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:02:28.522174Z",
     "iopub.status.busy": "2021-12-09T16:02:28.521128Z",
     "iopub.status.idle": "2021-12-09T16:02:28.532659Z",
     "shell.execute_reply": "2021-12-09T16:02:28.533696Z"
    },
    "id": "2B8LZS1K9ZLg"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:02:28.537268Z",
     "iopub.status.busy": "2021-12-09T16:02:28.536239Z",
     "iopub.status.idle": "2021-12-09T16:02:28.553495Z",
     "shell.execute_reply": "2021-12-09T16:02:28.553495Z"
    },
    "id": "4ffbGcIl9ZLg"
   },
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:02:28.559366Z",
     "iopub.status.busy": "2021-12-09T16:02:28.558341Z",
     "iopub.status.idle": "2021-12-09T16:02:36.473356Z",
     "shell.execute_reply": "2021-12-09T16:02:36.474354Z"
    },
    "id": "_OcE5fVyBXpR"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install shap\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ER39Qtaf3A7W"
   },
   "source": [
    "# **Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5On0lhwx3A7X"
   },
   "source": [
    "Here we have some functions used in the project, the ones for general use are for creating new columns in the data and reading and saving datasets. The functions for the models contain the preprocessing, division into training and test data, validation of the regressions and plot of the graph with the features importances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icLZ5H1_3A7X"
   },
   "source": [
    "## **General**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:02:36.479961Z",
     "iopub.status.busy": "2021-12-09T16:02:36.479401Z",
     "iopub.status.idle": "2021-12-09T16:02:36.488673Z",
     "shell.execute_reply": "2021-12-09T16:02:36.487673Z"
    },
    "id": "NyOlO2_LSFvo"
   },
   "outputs": [],
   "source": [
    "def read_csv(path):\n",
    "    \"\"\"\"Read csv files\n",
    "\n",
    "    :param path str: path to the csv file.\n",
    "\n",
    "    :return: dataframe from the csv file.\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(path, dtype={'M': str})\n",
    "    print(df.shape)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:02:36.491523Z",
     "iopub.status.busy": "2021-12-09T16:02:36.491523Z",
     "iopub.status.idle": "2021-12-09T16:02:36.504519Z",
     "shell.execute_reply": "2021-12-09T16:02:36.504519Z"
    },
    "id": "mWbFWcfPRb76"
   },
   "outputs": [],
   "source": [
    "def save_csv(df, path):\n",
    "    \"\"\"Save csv files\n",
    "\n",
    "    :param df pd.DataFrame: dataframe to be saved.\n",
    "    :param path str: path to save the csv file.\n",
    "\n",
    "    :return: no value\n",
    "    :rtype: none\n",
    "    \"\"\"\n",
    "\n",
    "    df.to_csv(path, encoding='utf-8', index=False)\n",
    "    print('CSV file saved successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:02:36.512914Z",
     "iopub.status.busy": "2021-12-09T16:02:36.511908Z",
     "iopub.status.idle": "2021-12-09T16:02:36.522853Z",
     "shell.execute_reply": "2021-12-09T16:02:36.522853Z"
    },
    "id": "XWsQFaA9Rq2I"
   },
   "outputs": [],
   "source": [
    "def variables_preprocessing(df):\n",
    "    \"\"\"Do some preprocessing on the DataFrame like strings splits, fill NaN values,\n",
    "    replace values and drop some columns.\n",
    "\n",
    "    :param df pd.DataFrame: DataFrame to be preprocessed.\n",
    "\n",
    "    :return: DataFrame after be preprocessed and get some columns removed\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    df_aux = df.copy()\n",
    "    no_info = '**Sem informação**'\n",
    "\n",
    "    # Excluding ECGRUP with X and Y values\n",
    "    df_aux = df_aux[~df_aux.ECGRUP.isin(['X','Y'])]\n",
    "\n",
    "    # Excluding C44 topographies (with morphologies between 80101 and 81103)\n",
    "    df_aux = df_aux[~((df_aux.TOPOGRUP == 'C44') & (df_aux.MORFO >= 80101) & (df_aux.MORFO <= 81103))]\n",
    "\n",
    "    # REGISTRADO\n",
    "    df_aux.REGISTRADO.fillna(99, inplace=True)\n",
    "\n",
    "    # DRS\n",
    "    DRS_expand = df_aux.DRS.str.split(' ', expand=True)\n",
    "    df_aux['DRS'] = DRS_expand[1]\n",
    "    df_aux.DRS.fillna(0, inplace=True)\n",
    "\n",
    "    # META\n",
    "    df_aux.META01.fillna(no_info, inplace=True)\n",
    "    df_aux.META02.fillna(no_info, inplace=True)\n",
    "\n",
    "    # REC\n",
    "    df_aux.REC01.fillna(no_info, inplace=True)\n",
    "    df_aux.REC02.fillna(no_info, inplace=True)\n",
    "    df_aux.REC03.fillna(no_info, inplace=True)\n",
    "\n",
    "    # PT\n",
    "    df_aux.PT = df_aux.PT.str.upper()\n",
    "    df_aux.PT.fillna(no_info, inplace=True)\n",
    "\n",
    "    # PN\n",
    "    df_aux.PN.fillna(no_info, inplace=True)\n",
    "\n",
    "    # PM\n",
    "    df_aux.PM.fillna(no_info, inplace=True)\n",
    "\n",
    "    col = df_aux.columns\n",
    "    drop_cols = ['S','QUIMIOANT','HORMOANT','TMOANT','IMUNOANT','OUTROANT','UFNASC',\n",
    "                'CICISUBGRU','CICIGRUP','CICI','META04','META03','REC04','CIDADE',\n",
    "                'DESCTOPO','DESCMORFO','INSTORIG','OUTRACLA']\n",
    "\n",
    "    col = col.drop(drop_cols)\n",
    "\n",
    "    return df_aux[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:02:36.530560Z",
     "iopub.status.busy": "2021-12-09T16:02:36.529540Z",
     "iopub.status.idle": "2021-12-09T16:02:36.543365Z",
     "shell.execute_reply": "2021-12-09T16:02:36.543365Z"
    },
    "id": "3QGBusZ-RyZT"
   },
   "outputs": [],
   "source": [
    "def get_dates_diff(df, dates_list):\n",
    "    \"\"\"Get the difference, in days, between columns with dates\n",
    "\n",
    "    :param df pd.DataFrame: DataFrame to get the dates difference.\n",
    "    :param dates_list list: list with the name of date columns.\n",
    "\n",
    "    :return: DataFrame with dates difference in nine new columns \n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    df_aux = df.copy()\n",
    "    \n",
    "    df_aux.dropna(subset=['DTTRAT', 'DTULTINFO'], inplace=True)\n",
    "    \n",
    "    for c in dates_list:\n",
    "        if c in ['DTTRAT', 'DTULTINFO', 'DTRECIDIVA']: # Has a different date format \n",
    "            fmt = '%Y-%m-%d %H:%M:%S'\n",
    "        else:\n",
    "            fmt = '%Y-%m-%d'\n",
    "        df_aux[c] = pd.to_datetime(df_aux[c], format=fmt)\n",
    "        \n",
    "    df_aux['CONSDIAG'] = (df_aux.DTDIAG - df_aux.DTCONSULT).dt.days\n",
    "    df_aux['DIAGTRAT'] = (df_aux.DTTRAT - df_aux.DTDIAG).dt.days\n",
    "    df_aux['TRATCONS'] = (df_aux.DTTRAT - df_aux.DTCONSULT).dt.days\n",
    "\n",
    "    #   df_aux['RECCONS'] = (df_aux.DTRECIDIVA - df_aux.DTCONSULT).dt.days\n",
    "    #   df_aux['RECDIAG'] = (df_aux.DTRECIDIVA - df_aux.DTDIAG).dt.days\n",
    "    #   df_aux['RECTRAT'] = (df_aux.DTRECIDIVA - df_aux.DTTRAT).dt.days\n",
    "\n",
    "    df_aux['ULTICONS'] = (df_aux.DTULTINFO - df_aux.DTCONSULT).dt.days\n",
    "    df_aux['ULTIDIAG'] = (df_aux.DTULTINFO - df_aux.DTDIAG).dt.days\n",
    "    df_aux['ULTITRAT'] = (df_aux.DTULTINFO - df_aux.DTTRAT).dt.days\n",
    "\n",
    "    df_aux.drop(columns=['DTCONSULT', 'DTDIAG', 'DTTRAT', 'DTRECIDIVA', 'DTULTINFO',\n",
    "                         'DTPREENCH'],\n",
    "                inplace=True)\n",
    "\n",
    "    return df_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:02:36.548318Z",
     "iopub.status.busy": "2021-12-09T16:02:36.548318Z",
     "iopub.status.idle": "2021-12-09T16:02:36.562992Z",
     "shell.execute_reply": "2021-12-09T16:02:36.564000Z"
    },
    "id": "9HkiH97zR5Ik"
   },
   "outputs": [],
   "source": [
    "def get_labels(df):\n",
    "    \"\"\"Create death labels acording to the last information year.\n",
    "\n",
    "    :param df pd.DataFrame: dataframe to be processed.\n",
    "\n",
    "    :return: DataFrame with the new labels\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    df_aux = df.copy()\n",
    "\n",
    "    df_aux['obito_geral'] = 0\n",
    "    df_aux['obito_cancer'] = 0\n",
    "\n",
    "    df_aux['vivo_ano1'] = 0\n",
    "    df_aux['vivo_ano3'] = 0\n",
    "    df_aux['vivo_ano5'] = 0 \n",
    "    \n",
    "    df_aux.loc[df_aux.ULTINFO > 2, 'obito_geral'] = 1\n",
    "\n",
    "    df_aux.loc[df_aux.ULTINFO == 3, 'obito_cancer'] = 1\n",
    "\n",
    "    df_aux.loc[df_aux.ULTIDIAG > 365, 'vivo_ano1'] = 1\n",
    "    df_aux.loc[df_aux.ULTIDIAG > 3*365, 'vivo_ano3'] = 1\n",
    "    df_aux.loc[df_aux.ULTIDIAG > 5*365, 'vivo_ano5'] = 1\n",
    "\n",
    "    return df_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:02:36.569272Z",
     "iopub.status.busy": "2021-12-09T16:02:36.568239Z",
     "iopub.status.idle": "2021-12-09T16:02:36.578758Z",
     "shell.execute_reply": "2021-12-09T16:02:36.579757Z"
    },
    "id": "T7Q6YHhDR7xE"
   },
   "outputs": [],
   "source": [
    "def get_label_rec(df):\n",
    "    \"\"\"Create the labels analyzing whether there was recurrence.\n",
    "    \n",
    "    :param df pd.DataFrame: dataframe to be processed.\n",
    "\n",
    "    :return: DataFrame with the new labels\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    df_aux = df.copy()\n",
    "\n",
    "    df_aux['ob_com_rec'] = 0\n",
    "    df_aux['ob_sem_rec'] = 0\n",
    "    df_aux['vivo_com_rec'] = 0\n",
    "    df_aux['vivo_sem_rec'] = 0\n",
    "\n",
    "    df_aux.loc[(df_aux.obito_geral == 1) & (df_aux.RECNENHUM == 1), 'ob_sem_rec'] = 1\n",
    "    df_aux.loc[(df_aux.obito_geral == 1) & (df_aux.RECNENHUM == 0), 'ob_com_rec'] = 1\n",
    "    df_aux.loc[(df_aux.obito_geral == 0) & (df_aux.RECNENHUM == 1), 'vivo_sem_rec'] = 1\n",
    "    df_aux.loc[(df_aux.obito_geral == 0) & (df_aux.RECNENHUM == 0), 'vivo_com_rec'] = 1\n",
    "\n",
    "    return df_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-_mGTn73A7d"
   },
   "source": [
    "## **Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:02:36.585333Z",
     "iopub.status.busy": "2021-12-09T16:02:36.584332Z",
     "iopub.status.idle": "2021-12-09T16:02:36.594663Z",
     "shell.execute_reply": "2021-12-09T16:02:36.593661Z"
    },
    "id": "wqSKVhPaRfOF"
   },
   "outputs": [],
   "source": [
    "def get_train_test(df, drop_cols, label, test_size=0.25, random_state=0):\n",
    "    \"\"\"Get features and label, and then returns train and test dataframes.\n",
    "\n",
    "    :param df pd.DataFrame: dataframe that will be splitted.\n",
    "    :param drop_cols list: columns to be removed from the DataFrame.\n",
    "    :param label str: name of the label column.\n",
    "    :param test_size float: size of test (default=0.25).\n",
    "    :param random_state int: value for train_test_split random_state (default=10).\n",
    "\n",
    "    :return: train and test DataFrames, X_train, X_test, y_train, y_test\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    df_aux = df.copy()\n",
    "\n",
    "    cols = df_aux.columns.drop(drop_cols)\n",
    "    lb = df_aux[label].copy()\n",
    "    cols = cols.drop(label)\n",
    "    feat = df_aux[cols]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feat, lb, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:02:36.602838Z",
     "iopub.status.busy": "2021-12-09T16:02:36.601833Z",
     "iopub.status.idle": "2021-12-09T16:02:36.613144Z",
     "shell.execute_reply": "2021-12-09T16:02:36.613990Z"
    },
    "id": "iZPpizU3SSU0"
   },
   "outputs": [],
   "source": [
    "def train_preprocessing(df, encoder_type='LabelEncoder', normalizer='StandardScaler',\n",
    "                        pca=False, pca_components=None, random_state=0):\n",
    "    \"\"\"Preprocessing the train dataset.\n",
    "\n",
    "    :param df pd.DataFrame: DataFrame to be preprocessed.\n",
    "    :param encoder_type string: Encoder type to use for categorical features (default='LabelEncoder').\n",
    "        options:\n",
    "        * 'LabelEncoder'\n",
    "        * 'OneHotEncoder'\n",
    "    :param normalizer str: which normalizer to be fitted to the data (default='StandardScaler').\n",
    "        options:\n",
    "        * 'StandardScaler'\n",
    "        * 'MinMaxScaler'\n",
    "        * 'MaxAbsScaler'\n",
    "        * 'QuantileTransformer'\n",
    "    :param pca bool: if want to use PCA components set True (default=False).\n",
    "    :param pca_components int: number of PCA components (default=None).\n",
    "    :param random_state int: value for pca random_state (default=10).\n",
    "\n",
    "    :return df: preprocessed train DataFrame \n",
    "    :rtype: pd.DataFrame\n",
    "    :return enc: trained LabelEncoder \n",
    "    :rtype: dict\n",
    "    :return norm: trained normalizer \n",
    "    :rtype: object\n",
    "    :return pca if param pca=True: trained PCA \n",
    "    :rtype: object\n",
    "    :return feat_cols: list with features names\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "\n",
    "    df_aux = df.copy()\n",
    "\n",
    "    list_categorical = df_aux.select_dtypes(include='object').columns\n",
    "\n",
    "    enc = dict()\n",
    "    if encoder_type == 'LabelEncoder':\n",
    "        for col in list_categorical:\n",
    "            enc[col] = LabelEncoder()\n",
    "            df_aux[col] = enc[col].fit_transform(df_aux[col])\n",
    "\n",
    "    elif encoder_type == 'OneHotEncoder':\n",
    "        for col in list_categorical:\n",
    "            enc[col] = OneHotEncoder(handle_unknown='ignore')\n",
    "            ohe_results = enc[col].fit_transform(df_aux[[col]])\n",
    "            df1 = pd.DataFrame(ohe_results.toarray(), columns=[f'{col}_{name}' for name in enc[col].categories_[0]], index=df_aux[col].index)\n",
    "            df_aux = df_aux.merge(df1, how='left', left_index=True, right_index=True)\n",
    "\n",
    "        df_aux.drop(columns=list_categorical, inplace=True)\n",
    "\n",
    "    feat_cols = df_aux.columns\n",
    "\n",
    "    if normalizer == 'StandardScaler':\n",
    "        norm = StandardScaler()\n",
    "    elif normalizer == 'MinMaxScaler':\n",
    "        norm = MinMaxScaler((0, 1))\n",
    "    elif normalizer == 'MaxAbsScaler':\n",
    "        norm = MaxAbsScaler()\n",
    "    elif normalizer == 'QuantileTransformer':\n",
    "        norm = QuantileTransformer(output_distribution='normal')\n",
    "    \n",
    "    df_aux = norm.fit_transform(df_aux)\n",
    "\n",
    "    if pca:\n",
    "        pca = PCA(pca_components, random_state=random_state)\n",
    "        df_aux = pca.fit_transform(df_aux)\n",
    "\n",
    "        return df_aux, enc, norm, pca, feat_cols\n",
    "\n",
    "    else:\n",
    "        return df_aux, enc, norm, feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:02:36.620790Z",
     "iopub.status.busy": "2021-12-09T16:02:36.620790Z",
     "iopub.status.idle": "2021-12-09T16:02:36.633191Z",
     "shell.execute_reply": "2021-12-09T16:02:36.633191Z"
    },
    "id": "2zwWCfmaSXXy"
   },
   "outputs": [],
   "source": [
    "def test_preprocessing(df, enc, norm, encoder_type='LabelEncoder', pca=None):\n",
    "    \"\"\"Preprocessing the test dataset.\n",
    "\n",
    "    :param df pd.DataFrame: DataFrame to be preprocessed.\n",
    "    :param enc: trained encoder with the categorical features.\n",
    "    :param norm: trained normalizer.\n",
    "    :param encoder_type string: Encoder type to use for categorical features (default='LabelEncoder').\n",
    "        options:\n",
    "        * 'LabelEncoder'\n",
    "        * 'OneHotEncoder'\n",
    "    :param pca: trained PCA (default=None).\n",
    "\n",
    "    :return: preprocessed test DataFrame \n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    df_aux = df.copy()\n",
    "\n",
    "    df_aux.fillna(0, inplace=True)\n",
    "\n",
    "    list_categorical = df_aux.select_dtypes(include='object').columns\n",
    "\n",
    "    if encoder_type == 'LabelEncoder':\n",
    "        for col in list_categorical:\n",
    "            df_aux.loc[~df_aux[col].isin(enc[col].classes_), col] = -1 \n",
    "            df_aux.loc[df_aux[col].isin(enc[col].classes_), col] = enc[col].transform(df_aux[col][df_aux[col].isin(enc[col].classes_)])\n",
    "    \n",
    "    elif encoder_type == 'OneHotEncoder':\n",
    "        for col in list_categorical:\n",
    "            ohe_results = enc[col].transform(df_aux[[col]])\n",
    "            df1 = pd.DataFrame(ohe_results.toarray(), columns=[f'{col}_{name}' for name in enc[col].categories_[0]], index=df_aux[col].index)\n",
    "            df_aux = df_aux.merge(df1, how='left', left_index=True, right_index=True)\n",
    "\n",
    "        df_aux.drop(columns=list_categorical, inplace=True)\n",
    "\n",
    "    df_aux = norm.transform(df_aux)\n",
    "\n",
    "    if pca != None:\n",
    "        df_aux = pca.transform(df_aux)\n",
    "\n",
    "    return df_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:02:36.645133Z",
     "iopub.status.busy": "2021-12-09T16:02:36.644105Z",
     "iopub.status.idle": "2021-12-09T16:02:36.653029Z",
     "shell.execute_reply": "2021-12-09T16:02:36.652003Z"
    },
    "id": "gbGi5xLoSbsk"
   },
   "outputs": [],
   "source": [
    "def preprocessing(df, cols_drop, label, test_size=0.25, encoder_type='LabelEncoder',\n",
    "                  norm_name='StandardScaler', pca=False, pca_components=None, \n",
    "                  balance_data=True, group_years=False, first_year=None, \n",
    "                  last_year=None, morpho3=False, random_state=0):\n",
    "  \n",
    "    \"\"\"Preprocessing the train and test datasets.\n",
    "\n",
    "    :param df pd.DataFrame: DataFrame to be preprocessed.\n",
    "    :param cols_drop list: list of columns to be dropped from dataset.\n",
    "    :param label string: name of the column that will be the label.\n",
    "    :param test_size float: size of test set (default=0.25).\n",
    "    :param encoder_type string: Encoder type to use for categorical features (default='LabelEncoder').\n",
    "        options:\n",
    "        * 'LabelEncoder'\n",
    "        * 'OneHotEncoder'\n",
    "    :param normalizer str: which normalizer to be fitted to the data (default='StandardScaler').\n",
    "        - options:\n",
    "        * 'StandardScaler';\n",
    "        * 'MinMaxScaler';\n",
    "        * 'MaxAbsScaler';\n",
    "        * 'PowerTransformer';\n",
    "        * 'QuantileTransformer'.\n",
    "    :param pca bool: if want to use PCA components set True (default=False).\n",
    "    :param pca_components int: number of PCA components (default=None).\n",
    "    :param balance_data bool: balance the data using oversampling (default=True).\n",
    "    :param group_years bool: create a subset with years grouped (default=False).\n",
    "    :param first_year int: first year of the grouped years. Ignored if group_years = False.\n",
    "    :param last_year int: last year of the grouped years. Ignored if group_years = False.\n",
    "    :param morpho3 bool: use only morphologies that the last number is equal to 3 (default=False).\n",
    "    :param random_state int: value for pca random_state (default=10).\n",
    "\n",
    "    :return X_train_: preprocessed train DataFrame \n",
    "    :rtype: pd.DataFrame\n",
    "    :return X_test_: preprocessed test DataFrame \n",
    "    :rtype: pd.DataFrame\n",
    "    :return y_train_: preprocessed train label \n",
    "    :rtype: pd.DataFrame\n",
    "    :return y_test: preprocessed test label \n",
    "    :rtype: pd.DataFrame\n",
    "    :return feat_cols: list with the features columns names\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "\n",
    "    df_aux = df.copy()\n",
    "\n",
    "    # Morphology 3\n",
    "    if morpho3:\n",
    "        df_aux['comportamento'] = [int(repr(i)[-1]) for i in df_aux.MORFO]\n",
    "        df_aux = df_aux[df_aux.comportamento == 3].copy()\n",
    "        df_aux.drop(columns='comportamento', inplace=True)\n",
    "\n",
    "    # Grouped years\n",
    "    if group_years and first_year != None and last_year != None:\n",
    "        df_aux = df_aux[(df_aux.ANODIAG >= first_year) & (df_aux.ANODIAG <= last_year)].copy()\n",
    "        \n",
    "    # Train Test split\n",
    "    X_train, X_test, y_train, y_test = get_train_test(df_aux, cols_drop, label, test_size, \n",
    "                                                      random_state=random_state)\n",
    "\n",
    "    # Preprocessing\n",
    "    if pca and pca_components != None:\n",
    "        X_train_enc, enc, norm, pca, feat_cols = train_preprocessing(X_train, encoder_type=encoder_type, \n",
    "                                                                     normalizer=norm_name, pca=pca,\n",
    "                                                                     pca_components=pca_components,\n",
    "                                                                     random_state=random_state)\n",
    "        X_test_ = test_preprocessing(X_test, enc, norm, \n",
    "                                     encoder_type, pca)\n",
    "\n",
    "    else:\n",
    "        X_train_enc, enc, norm, feat_cols = train_preprocessing(X_train, encoder_type=encoder_type,\n",
    "                                                     normalizer=norm_name)\n",
    "        X_test_ = test_preprocessing(X_test, enc, norm, \n",
    "                                     encoder_type)\n",
    "\n",
    "    # Balancing\n",
    "    if balance_data:\n",
    "        X_train_, y_train_ = SMOTE(random_state=random_state).fit_resample(X_train_enc, y_train)\n",
    "    \n",
    "    else:\n",
    "        X_train_, y_train_ = X_train_enc, y_train\n",
    "\n",
    "    print(f'X_train = {X_train_.shape}, X_test = {X_test_.shape}')\n",
    "    print(f'y_train = {y_train_.shape}, y_test = {y_test.shape}')\n",
    "\n",
    "    return X_train_, X_test_, y_train_, y_test, feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:02:36.656533Z",
     "iopub.status.busy": "2021-12-09T16:02:36.656533Z",
     "iopub.status.idle": "2021-12-09T16:02:36.672976Z",
     "shell.execute_reply": "2021-12-09T16:02:36.672976Z"
    },
    "id": "7IStl5ugSdVd"
   },
   "outputs": [],
   "source": [
    "def show_tree(model, feat_cols, max_depth=3, estimator=0):\n",
    "    \"\"\"Show the Random Forest tree\n",
    "\n",
    "    :param model: machine learning model.\n",
    "    :param feat_cols list: list of the features used in the model training.\n",
    "    :param max_depth int: max_depth to show in the tree (default = 3).\n",
    "    :param estimator int: number of the estimator do show the tree (default = 0).\n",
    "\n",
    "    :return: no value\n",
    "    :rtype: none\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize = (22,10))\n",
    "    tree.plot_tree(model.estimators_[estimator],\n",
    "                   feature_names = feat_cols,\n",
    "                   filled = True, \n",
    "                   max_depth=max_depth);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:02:36.677098Z",
     "iopub.status.busy": "2021-12-09T16:02:36.677098Z",
     "iopub.status.idle": "2021-12-09T16:02:36.693414Z",
     "shell.execute_reply": "2021-12-09T16:02:36.693414Z"
    },
    "id": "wnxKOimRSjCi"
   },
   "outputs": [],
   "source": [
    "def plot_feat_importances(model, feat_cols, n=10):\n",
    "    \"\"\"Shows the features importances for the model.\n",
    "\n",
    "    :param model: machine learning model.\n",
    "    :param feat_cols list: list of the features used in the model training.\n",
    "    :param n int: number of features to be shown (default=10).\n",
    "\n",
    "    :return: no value\n",
    "    :rtype: none\n",
    "    \"\"\"\n",
    "\n",
    "    feat_import = pd.Series(model.feature_importances_, index=feat_cols)\n",
    "    feat_import.nlargest(n).plot(kind='barh', figsize=(10, 8))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:02:36.699344Z",
     "iopub.status.busy": "2021-12-09T16:02:36.699344Z",
     "iopub.status.idle": "2021-12-09T16:02:36.709357Z",
     "shell.execute_reply": "2021-12-09T16:02:36.708274Z"
    },
    "id": "gwHb0Yo3Sm-M"
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Plot the ROC curve for train and test sets.\n",
    "\n",
    "    :param model: Trained machine learning model.\n",
    "    :param X_train: Features of training set.\n",
    "    :param X_test: Features of test set.\n",
    "    :param y_train: Label of training set.\n",
    "    :param y_test: Label of test set.\n",
    "\n",
    "    :return: no value\n",
    "    :rtype: None\n",
    "    \"\"\"\n",
    "    probas_train = model.predict_proba(X_train)[:, 1]\n",
    "    probas_test = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    fp_train, tp_train, _ = roc_curve(y_train, probas_train)\n",
    "    fp_test, tp_test, _ = roc_curve(y_test, probas_test)\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(fp_train, tp_train, 'b', label=f'Train (AUC = {auc(fp_train, tp_train):.3f})')\n",
    "    plt.plot(fp_test, tp_test, 'r', label=f'Test (AUC = {auc(fp_test, tp_test):.3f})')\n",
    "    plt.plot(np.linspace(0, 1, 100),\n",
    "             np.linspace(0, 1, 100),\n",
    "             label='Baseline',\n",
    "             linestyle='--', \n",
    "             color='k')\n",
    "    plt.xlabel('False Positives')\n",
    "    plt.ylabel('True Positives')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pcL2DGLg8DF-"
   },
   "source": [
    "# **References**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxjnLWTc8GzJ"
   },
   "source": [
    "[Pandas](https://pandas.pydata.org/docs/reference/index.html)\n",
    "\n",
    "[Seaborn](https://seaborn.pydata.org/api.html)\n",
    "\n",
    "[Matplotlib](https://matplotlib.org/stable/gallery/index.html)\n",
    "\n",
    "[Plotly](https://plotly.com/python/)\n",
    "\n",
    "[sklearn preprocessing](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py)\n",
    "\n",
    "[sklearn train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split)\n",
    "\n",
    "[imblearn](https://imbalanced-learn.org/stable/references/index.html)\n",
    "\n",
    "[Random Forest Classifier and Regressor](https://scikit-learn.org/stable/modules/ensemble.html#forests-of-randomized-trees)\n",
    "\n",
    "[Confusion Matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html#sklearn.metrics.plot_confusion_matrix)\n",
    "\n",
    "[Metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)\n",
    "\n",
    "[XGBoost](https://xgboost.readthedocs.io/en/latest/python/python_intro.html)\n",
    "\n",
    "[XGBoost for Regression Machine Learning Mastery](https://machinelearningmastery.com/xgboost-for-regression/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "zlGZnyBQ_dG0",
    "Wc8O5Laa3A7Q",
    "ER39Qtaf3A7W",
    "icLZ5H1_3A7X",
    "r-_mGTn73A7d",
    "pcL2DGLg8DF-"
   ],
   "name": "Cancer Libraries and functions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
